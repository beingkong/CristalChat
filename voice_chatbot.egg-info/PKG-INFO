Metadata-Version: 2.1
Name: voice-chatbot
Version: 0.1.0
Summary: A multi-module voice AI chat system
Home-page: https://github.com/yourusername/voice-chatbot
Author: AI Assistant
Author-email: example@example.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown

# Voice Chatbot

A multi-module voice AI chat system with streaming speech input processing, language understanding and generation, and speech output synthesis.

## Features

- **Real-time Voice Interaction**: Full-duplex voice communication with barge-in capability
- **Emotion Recognition**: Detects user emotions from voice and adapts responses accordingly
- **Streaming Processing**: Processes speech incrementally to reduce latency
- **Modular Architecture**: Easily replaceable components for flexibility and upgradability

## Architecture

The system consists of the following modules:

1. **Voice Activity Detection (VAD)**: Detects when the user is speaking
2. **Automatic Speech Recognition (ASR)**: Converts speech to text using SenseVoice
3. **Speech Emotion Recognition (SER)**: Detects emotions in speech
4. **Large Language Model (LLM)**: Generates responses using Qwen-14B
5. **Text-to-Speech (TTS)**: Converts text to speech using F5-TTS
6. **Audio Player**: Handles audio playback
7. **Orchestrator**: Coordinates all components

## Installation

### Prerequisites

- Python 3.8 or higher
- CUDA-compatible GPU (for optimal performance)

### Install from source

```bash
# Clone the repository
git clone https://github.com/yourusername/voice-chatbot.git
cd voice-chatbot

# Install the package
pip install -e .
```

## Usage

### Basic Usage

```bash
# Start the voice chatbot with default settings
voice-chatbot
```

### Advanced Usage

```bash
# Start with a custom prompt template
voice-chatbot --prompt-template /path/to/prompt.txt

# Use a reference voice for TTS
voice-chatbot --voice-ref /path/to/voice.wav

# Set logging level
voice-chatbot --log-level DEBUG
```

## Development

### Project Structure

```
voice_chatbot/
├── __init__.py
├── main.py                     # Application entry point
├── vad.py                      # Voice Activity Detection module
├── asr.py                      # Automatic Speech Recognition module
├── ser.py                      # Speech Emotion Recognition module
├── llm.py                      # Large Language Model module
├── tts.py                      # Text-to-Speech module
├── audio_player.py             # Audio playback module
├── orchestrator.py             # Scheduling management module
├── utils/                      # Utility functions
│   ├── __init__.py
│   └── text_utils.py
└── prompts/                    # Prompt templates
    └── assistant_prompt.txt
```

### Adding New Components

The modular architecture makes it easy to replace or upgrade individual components:

1. Create a new module that implements the same interface as the existing one
2. Update the orchestrator to use your new module
3. Test the integration

## License

MIT

## Acknowledgments

This project uses the following open-source projects:

- [SenseVoice](https://huggingface.co/iic/senseVoice) for speech recognition and emotion detection
- [Qwen](https://huggingface.co/Qwen) for language understanding and generation
- [F5-TTS](https://github.com/F5-TTS) for text-to-speech synthesis
